# Even GPT - Native macOS App for Even Realities G1 Glasses

A native Swift/SwiftUI macOS application that acts as a GPT-4 wrapper for Even Realities G1 AR glasses. Voice input from glasses â†’ GPT-4 processing â†’ visual response on glasses display.

## Features

- ğŸ¤ **Voice Input** - Hold app button or long-press glasses TouchBar to speak questions
- ğŸ¤– **GPT-4 Integration** - Powered by OpenAI's GPT-4 Turbo API
- ğŸ¥½ **Dual Display** - Responses shown in macOS app AND on AR glasses
- ğŸ“¡ **Bluetooth Connectivity** - Direct BLE communication with G1 glasses
- ğŸ—£ï¸ **On-Device Speech Recognition** - Privacy-focused local speech processing
- ğŸ“ **Chat History** - Track all Q&A sessions

## Requirements

- **macOS 11.0+** (Big Sur or later)
- **Xcode 14.0+**
- **Even Realities G1 Glasses**
- **OpenAI API Key** ([Get one here](https://platform.openai.com/api-keys))

## Quick Start

### 1. Configure API Key

Create a `.env` file in the project root:

```bash
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

### 2. Open in Xcode

```bash
cd macos
open Runner.xcodeproj
```

### 3. Build & Run

- Press **âŒ˜R** or click the â–¶ï¸ Play button
- Grant permissions when prompted:
  - âœ… Bluetooth
  - âœ… Microphone
  - âœ… Speech Recognition

### 4. Connect Glasses

1. Click the connection status in the app
2. Click "Scan for Glasses"
3. Select your G1 glasses from the list
4. Wait for "Connected" status

### 5. Ask Questions

**From App:**
- Type question in text field â†’ Click Send

**From Glasses:**
- Long-press left TouchBar â†’ Speak â†’ Release
- View response on glasses display and in app

## Project Structure

```
macos/
â”œâ”€â”€ Runner.xcodeproj/           # Xcode project
â””â”€â”€ Runner/
    â”œâ”€â”€ EvenGPTApp.swift       # App entry point
    â”œâ”€â”€ AppDelegate.swift       # App lifecycle & BLE event handlers
    â”œâ”€â”€ ContentView.swift       # SwiftUI main interface
    â”œâ”€â”€ ChatViewModel.swift     # State management & chat logic
    â”œâ”€â”€ OpenAIService.swift     # GPT-4 API client
    â”œâ”€â”€ BluetoothManager.swift  # BLE protocol for G1 glasses
    â”œâ”€â”€ SpeechStreamRecognizer.swift  # Voice recognition
    â”œâ”€â”€ ServiceIdentifiers.swift      # BLE UUIDs
    â”œâ”€â”€ GattProtocal.swift     # BLE helpers
    â”œâ”€â”€ PcmConverter.h/m       # Audio format conversion
    â”œâ”€â”€ Runner-Bridging-Header.h     # Obj-C bridge
    â”œâ”€â”€ lc3/                   # LC3 audio codec (34 files)
    â”œâ”€â”€ Assets.xcassets/       # App icons
    â”œâ”€â”€ Info.plist            # App metadata
    â””â”€â”€ *.entitlements        # Permissions
```

## BLE Protocol (Even G1)

### Commands Sent to Glasses

| Command | Purpose | Format |
|---------|---------|--------|
| `0x0E 0x01` | Activate microphone | `[0x0E, 0x01]` |
| `0x0E 0x00` | Deactivate microphone | `[0x0E, 0x00]` |
| `0x4E ...` | Send text/AI response | See below |

### Text Display Protocol (0x4E)

```
[0x4E, seq, total_pkg, current_pkg, newscreen, pos_hi, pos_lo, cur_page, max_page, ...text..., crc_lo, crc_hi]
```

**Fields:**
- `newscreen`: `0x31` = new content + AI displaying
- `cur_page` / `max_page`: Pagination support
- CRC-16 checksum for data integrity

### Commands Received from Glasses

| Command | Gesture | Action |
|---------|---------|--------|
| `0xF5 0x00` | Double tap | Exit/close feature |
| `0xF5 0x01` | Single tap | Page navigation |
| `0xF5 0x11` | Long-press left | Start voice input |
| `0xF1 ...` | Audio stream | LC3-encoded mic data |

## Architecture

### Voice Input Flow

```
Glasses (Long-press)
  â†’ BLE: 0xF5 0x11
  â†’ App sends: 0x0E 0x01 (activate mic)
  â†’ Glasses streams LC3 audio
  â†’ LC3 Decoder â†’ PCM
  â†’ Speech Recognition
  â†’ GPT-4 API
  â†’ Response â†’ 0x4E packets
  â†’ Glasses Display
```

### Components

- **SwiftUI**: Modern declarative UI
- **Combine**: Reactive state management
- **CoreBluetooth**: BLE communication
- **Speech Framework**: On-device speech recognition
- **LC3 Codec**: Bluetooth LE audio codec (C library)
- **URLSession**: Async/await API calls

## Development

### Key Files

**UI Layer:**
- `EvenGPTApp.swift` - App definition & window config
- `ContentView.swift` - Main UI (scanning, chat, input)
- `ChatViewModel.swift` - Business logic & state

**Services:**
- `OpenAIService.swift` - GPT-4 API client
- `BluetoothManager.swift` - G1 BLE protocol
- `SpeechStreamRecognizer.swift` - Voice â†’ text

**Native Code:**
- `PcmConverter.m` - LC3 â†’ PCM audio conversion
- `lc3/*.c` - LC3 codec implementation

### Customization

**Adjust GPT Prompts:**

Edit `OpenAIService.swift` line 50:
```swift
"messages": [
    ["role": "system", "content": "Your custom system prompt"],
    ["role": "user", "content": question]
]
```

**Change Response Length:**

Edit `OpenAIService.swift` line 54:
```swift
"max_tokens": 500  // Adjust for longer/shorter responses
```

**UI Styling:**

Modify `ContentView.swift` colors, fonts, layout

## Troubleshooting

### Glasses Won't Connect
- Ensure glasses are powered on
- Check macOS Bluetooth is enabled
- Try restarting glasses and app
- Check System Settings â†’ Bluetooth for permissions

### No Voice Recognition
- Grant microphone permission in System Settings â†’ Privacy & Security
- Grant speech recognition permission
- Check console for speech recognition errors
- Verify glasses mic is sending data (check for PCM logs)

### API Errors
- Verify `.env` file exists with valid API key
- Check internet connection
- Review OpenAI API quotas/billing
- Check console for detailed error messages

### Glasses Display Not Working
- Verify protocol format matches G1 specs
- Check console for "âœ… Sent XXX bytes" messages
- Ensure CRC checksum is correct
- Try shorter text responses

### Check Console Logs

Press **âŒ˜â‡§Y** in Xcode to open console and look for:
- `ğŸ¤` Voice recognition logs
- `ğŸ“¤` BLE send logs
- `âœ…` Success indicators
- `âŒ` Error messages

## License

See [LICENSE](LICENSE) file.

## Credits

Built with:
- [Even Realities G1 SDK](https://docs.evenrealities.com/)
- [OpenAI API](https://platform.openai.com/)
- LC3 codec implementation

---

**Note**: This is a native Swift rewrite of the original Flutter demo app, optimized for macOS with enhanced BLE protocol handling and modern async/await patterns.
